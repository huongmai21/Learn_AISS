{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Truy cập vào google drive để có thể lấy dữ liệu\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NsnlUPmnWgW",
        "outputId": "5284fdff-c495-4f9c-ddff-4fa3f99d075b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/BaiThi2_Samsung"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZyeh3ORph4V",
        "outputId": "3bae2045-2772-4968-f766-3b880f991025"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/BaiThi2_Samsung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5GVYpNR2nvlD",
        "outputId": "ddd904ab-a600-4d25-a44c-2d5133ccaa54"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->bitsandbytes)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truy cập vào google drive để có thể lấy dữ liệu\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "!pwd  # Print current working directory to verify location\n",
        "!ls '/content/drive/MyDrive/BaiThi2_Samsung/TrainData' # List files in the directory\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import os\n",
        "\n",
        "# Đọc dữ liệu từ thư mục TrainData\n",
        "def read_data(folder):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    # Check if the directory exists\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Error: Directory '{folder}' does not exist.\")\n",
        "        return texts, labels\n",
        "\n",
        "    for filename in os.listdir(folder):\n",
        "        # Kiểm tra xem đây có phải là một tệp tin không\n",
        "        if os.path.isfile(os.path.join(folder, filename)):\n",
        "            label = 'spam' if 'spam' in filename else 'notspam'\n",
        "            try:\n",
        "                with open(os.path.join(folder, filename), 'r', encoding='utf-8') as file:\n",
        "                    texts.append(file.read())\n",
        "                    labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading file '{filename}': {e}\")\n",
        "    return texts, labels\n",
        "\n",
        "# Đường dẫn đến thư mục dữ liệu\n",
        "train_folder = '/content/drive/MyDrive/BaiThi2_Samsung/TrainData' # Update this path if needed\n",
        "\n",
        "# Đọc dữ liệu và nhãn\n",
        "texts, labels = read_data(train_folder)\n",
        "\n",
        "print(f\"Number of texts loaded: {len(texts)}\")  # Check if texts were loaded\n",
        "\n",
        "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
        "# Proceed with train_test_split only if texts were loaded\n",
        "if texts:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Tạo pipeline với TF-IDF và Naive Bayes\n",
        "    model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "\n",
        "    # Huấn luyện mô hình\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Dự đoán trên tập kiểm tra\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Đánh giá mô hình\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "else:\n",
        "    print(\"No texts were loaded. Please check the directory path and file contents.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbIEovTl_yUc",
        "outputId": "da7836b7-fafb-498e-9455-f2f9bd58272e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "notspam  spam\n",
            "Number of texts loaded: 0\n",
            "No texts were loaded. Please check the directory path and file contents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a PyTorch model named 'model'\n",
        "import torch\n",
        "\n",
        "# Đọc dữ liệu từ thư mục TestData_nolabel\n",
        "test_folder = '/content/drive/MyDrive/BaiThi2_Samsung/TestData_nolabel'\n",
        "test_texts = [open(os.path.join(test_folder, filename), 'r', encoding='utf-8').read() for filename in os.listdir(test_folder)]\n",
        "\n",
        "# Dự đoán nhãn\n",
        "with torch.no_grad(): # Disable gradient calculation for inference\n",
        "    # Assuming your model expects tokenized input (adjust as needed)\n",
        "    inputs = tokenizer(test_texts, return_tensors='pt', padding=True, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    predicted_labels = torch.argmax(outputs.logits, dim=1).tolist()  # Get predicted class indices\n",
        "\n",
        "# Lưu kết quả vào file\n",
        "for filename, label in zip(os.listdir(test_folder), predicted_labels):\n",
        "    print(f\"{filename},{label}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12o3n3z8A0QY",
        "outputId": "c61fa6d0-e80f-4ebe-daa1-6f4ee60578d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0_unknown.txt,1\n",
            "6_unknown.txt,1\n",
            "3_unknown.txt,1\n",
            "32_unknown.txt,1\n",
            "5_unknown.txt,1\n",
            "17_unknown.txt,1\n",
            "13_unknown.txt,0\n",
            "9_unknown.txt,1\n",
            "1_unknown.txt,0\n",
            "11_unknown.txt,1\n",
            "30_unknown.txt,0\n",
            "23_unknown.txt,0\n",
            "14_unknown.txt,1\n",
            "34_unknown.txt,0\n",
            "29_unknown.txt,1\n",
            "2_unknown.txt,1\n",
            "25_unknown.txt,0\n",
            "8_unknown.txt,0\n",
            "20_unknown.txt,0\n",
            "21_unknown.txt,0\n",
            "31_unknown.txt,0\n",
            "28_unknown.txt,0\n",
            "37_unknown.txt,0\n",
            "16_unknown.txt,0\n",
            "35_unknown.txt,1\n",
            "22_unknown.txt,1\n",
            "12_unknown.txt,0\n",
            "10_unknown.txt,1\n",
            "7_unknown.txt,0\n",
            "15_unknown.txt,1\n",
            "24_unknown.txt,1\n",
            "18_unknown.txt,0\n",
            "38_unknown.txt,1\n",
            "27_unknown.txt,1\n",
            "36_unknown.txt,0\n",
            "4_unknown.txt,1\n",
            "19_unknown.txt,0\n",
            "39_unknown.txt,0\n",
            "26_unknown.txt,1\n",
            "33_unknown.txt,0\n",
            "42_unknown.txt,0\n",
            "47_unknown.txt,1\n",
            "41_unknown.txt,1\n",
            "45_unknown.txt,0\n",
            "40_unknown.txt,0\n",
            "43_unknown.txt,1\n",
            "44_unknown.txt,1\n",
            "46_unknown.txt,1\n",
            "62_unknown.txt,1\n",
            "55_unknown.txt,0\n",
            "75_unknown.txt,1\n",
            "56_unknown.txt,1\n",
            "73_unknown.txt,1\n",
            "51_unknown.txt,1\n",
            "72_unknown.txt,1\n",
            "63_unknown.txt,1\n",
            "50_unknown.txt,1\n",
            "67_unknown.txt,1\n",
            "48_unknown.txt,1\n",
            "70_unknown.txt,1\n",
            "52_unknown.txt,1\n",
            "60_unknown.txt,0\n",
            "57_unknown.txt,0\n",
            "71_unknown.txt,0\n",
            "54_unknown.txt,0\n",
            "64_unknown.txt,0\n",
            "53_unknown.txt,0\n",
            "58_unknown.txt,1\n",
            "68_unknown.txt,1\n",
            "74_unknown.txt,1\n",
            "65_unknown.txt,1\n",
            "66_unknown.txt,0\n",
            "49_unknown.txt,0\n",
            "69_unknown.txt,1\n",
            "61_unknown.txt,1\n",
            "59_unknown.txt,1\n",
            "76_unknown.txt,1\n",
            "77_unknown.txt,0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lưu kết quả vào file CSV hoặc TXT\n",
        "output_file = '/content/drive/MyDrive/BaiThi2_Samsung/output_labels.txt'\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    for filename, label in zip(os.listdir(test_folder), predicted_labels): # Iterate over filenames and labels together\n",
        "        f.write(f\"{filename},{label}\\n\")\n",
        "\n",
        "print(f\"Labels have been saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fdQLUz2DEx-",
        "outputId": "23f9c968-d33d-456a-a2de-44511c82f684"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels have been saved to /content/drive/MyDrive/BaiThi2_Samsung/output_labels.txt\n"
          ]
        }
      ]
    }
  ]
}